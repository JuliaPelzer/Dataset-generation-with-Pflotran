{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the benchmark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate max. temperature of 2D Pflotran dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"benchmark_testcases_4/RUN_3/\"\n",
    "filename = os.path.join(folder, \"pflotran.h5\")\n",
    "with h5py.File(filename, \"r\") as file:\n",
    "    maxtemp = np.max(file['   4 Time  2.75000E+01 y']['Temperature [C]'])\n",
    "    temp_reshape = np.reshape(file['   4 Time  2.75000E+01 y']['Temperature [C]'], (20, 256), order='F')\n",
    "    print(maxtemp, np.where(temp_reshape==maxtemp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate max. temperature of groundtruth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"benchmark_dataset_3d_fine/RUN_3/\"\n",
    "filename = os.path.join(folder, \"pflotran.h5\")\n",
    "with h5py.File(filename, \"r\") as file:\n",
    "    maxtemp = np.max(file['   4 Time  2.75000E+01 y']['Temperature [C]'])\n",
    "    temp_reshape = np.reshape(file['   4 Time  2.75000E+01 y']['Temperature [C]'], (100, 1280, 5), order='F')\n",
    "    print(maxtemp, np.where(temp_reshape==maxtemp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate plume of 2D Pflotran dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"benchmark_testcases_4/RUN_3\"\n",
    "filename = os.path.join(folder, \"pflotran.h5\")\n",
    "with h5py.File(filename, \"r\") as file:\n",
    "    temp = file['   4 Time  2.75000E+01 y']['Temperature [C]']\n",
    "    temp = np.reshape(temp, (20, 256), order='F')\n",
    "    _, axes = plt.subplots(1,1,sharex=True,figsize=(20,3))\n",
    "    contours = plt.contourf(temp, levels=np.arange(10.6, 15.6, 1), cmap='RdBu_r')\n",
    "    path = contours.collections[0].get_paths()[0]\n",
    "    vertices = path.vertices\n",
    "# remove boundary values from vertices\n",
    "vertices = vertices[vertices[:,0] != 0]\n",
    "vertices = vertices[vertices[:,1] != 0]\n",
    "vertices = vertices[vertices[:,0] != 255]\n",
    "vertices = vertices[vertices[:,1] != 19]\n",
    "\n",
    "# plot path.vertices\n",
    "plt.plot(vertices[:,0], vertices[:,1], 'yo')\n",
    "\n",
    "print(\"max. width plume\", np.round((np.max(vertices[:,1])-np.min(vertices[:,1]))*5, 2))\n",
    "plume_len = np.round((np.max(vertices[:,0])-np.min(vertices[:,0]))*5, 2)\n",
    "# if plume_len < 0:\n",
    "#     plume_len = np.round(np.max(vertices[:,0])*5, 2)\n",
    "print(\"length plume\", plume_len)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate plume of groundtruth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"benchmark_dataset_3d_fine/RUN_0/\"\n",
    "filename = os.path.join(folder, \"pflotran.h5\")\n",
    "with h5py.File(filename, \"r\") as file:\n",
    "    temp = file['   4 Time  2.75000E+01 y']['Temperature [C]']\n",
    "    temp = np.reshape(temp, (100, 1280, 5), order='F')\n",
    "    _, axes = plt.subplots(1,1,sharex=True,figsize=(20,3))\n",
    "    contours = plt.contourf(temp[:,:,2], levels=np.arange(10.6, 15.6, 1), cmap='RdBu_r')\n",
    "    path = contours.collections[0].get_paths()[0]\n",
    "    vertices = path.vertices\n",
    "# remove boundary values from vertices\n",
    "vertices = vertices[vertices[:,0] != 0]\n",
    "vertices = vertices[vertices[:,1] != 0]\n",
    "vertices = vertices[vertices[:,0] != 1279]\n",
    "vertices = vertices[vertices[:,1] != 99]\n",
    "\n",
    "# plot path.vertices\n",
    "plt.plot(vertices[:,0], vertices[:,1], 'yo')\n",
    "\n",
    "print(\"max. width plume\", np.round((np.max(vertices[:,1])-np.min(vertices[:,1])), 2))\n",
    "plume_len = np.round(np.max(vertices[:,0])-np.min(vertices[:,0]), 2)\n",
    "print(\"length plume\", plume_len) #, np.min(vertices[:,0]), np.round((np.max(vertices[:,0])-0), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualisation_self import plot_sim\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "path_settings = \"benchmark_dataset_3d_fine\"\n",
    "path_run = \"benchmark_dataset_3d_fine/RUN_3\"\n",
    "case = \"3D\"\n",
    "\n",
    "plot_sim(path_settings=path_settings, path_run=path_run, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
